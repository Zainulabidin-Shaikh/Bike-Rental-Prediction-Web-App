ui: # user interface
  default_lookback_hours: 12
  update_interval_ms: 1000
  axis_font_color: "#222"

# 1ï¸âƒ£ ui: â†’ User Interface Settings

#   ğŸ’¡ What it does:

# Controls how the dashboard (like a web app) behaves

# default_lookback_hours: 12 â†’ Show last 12 hours of data by default
# update_interval_ms: 1000 â†’ Refresh every 1 second
# axis_font_color: "#222" â†’ Black font color

# ğŸ¯ Why?
# So you can tweak the UI without coding.

inference_api:
  host: localhost
  port: 5001
  endpoint: /run-inference

# 2ï¸âƒ£ inference_api: â†’ API Settings

# inference_api:
#   host: localhost
#   port: 5001
#   endpoint: /run-inference

# ğŸ’¡ What it does:

# Where your prediction API runs

# host: localhost â†’ Runs on your computer
# port: 5001 â†’ Youâ€™ll access it at http://localhost:5001
# endpoint: /run-inference â†’ Send POST requests to /run-inference

# ğŸ¯ Why?
# So you can change the port (e.g., to 8000) without editing code.


data_manager:
  raw_data_folder: './data/raw_data/'
  prod_data_folder: './data/prod_data/'
  raw_database_name: 'database.parquet'
  prod_database_name: 'database_prod.parquet'
  real_time_data_prod_name: 'real_time_data_prod.parquet'
  real_time_prediction_data_name: 'real_time_prediction.parquet'

# 3ï¸âƒ£ data_manager: â†’ Data Folder Settings

# ğŸ’¡ What it does:

# Tells the code where to find and save data
# raw_data_folder â†’ Where raw CSV/Parquet files are
# prod_database_name â†’ Name of the cleaned data file

# ğŸ¯ Why?

# If you move data to ./data_v2/, just change the config â€” not the code.

pipeline_runner:
  batch_size: 30
  model_path: 'models/prod/latest_model'
  first_timestamp: '2012-08-07 12:00:00'
  last_timestamp: '2012-12-31 23:00:00'
  time_increment: '1h'

# 4ï¸âƒ£ pipeline_runner: â†’ Automation Settings

# ğŸ’¡ What it does:

# Controls how the pipeline runs
# model_path â†’ Where to save/load the trained model
# first_timestamp â†’ Start date for simulation
# time_increment: '1h' â†’ Simulate hour by hour

# ğŸ¯ Why?

# So you can test with a small date range first, then scale up â€” no code change.

preprocessing:
  column_mapping:
    'season': 'season'
    'yr': 'year'
    'mnth': 'month'
    'hr': 'hour'
    'weekday': 'week_day'
    'workingday': 'working_day'
    'weathersit': 'weather'
    'temp': 'temperature'
    'atemp': 'temperature_feel'
    'hum': 'humidity'
    'windspeed': 'wind_speed'
    'cnt': 'bike_count'

  drop_columns: [
    'datetime', 'year', 'casual', 'registered'
  ]

# 5ï¸âƒ£ preprocessing: â†’ Data Cleaning Rules

# ğŸ’¡ What it does:

# column_mapping: Rename columns (e.g., yr â†’ year)
# drop_columns: Remove unneeded columns

# ğŸ¯ Why?

# So if you later want to keep casual, just remove it from the list â€” no code edit.


feature_engineering:
  lag_params:
    'bike_count': [1, 2, 22, 23]
    'hour': [1, 2, 3]
    'week_day': [1, 2, 3]
    'weather': [1, 2, 3]
    'temperature': [1, 2, 3]
    'humidity': [1, 2, 3]

# 6ï¸âƒ£ feature_engineering: â†’ Lag Features

# ğŸ’¡ What it does:

# Says: "Create lag features for bike_count at 1hr, 2hr, 22hr, 23hr ago"
# Why 22 and 23? To capture daily patterns (e.g., yesterdayâ€™s rush hour)

# ğŸ¯ Why?

# So you can experiment with lags without touching code.

training:
  target_params:
    shift_period: 1
    target_column: 'bike_count'
    new_target_name: 'target'
  train_fraction: 0.85
  iterations: 100
  loss_function: RMSE
  verbose: 0
  early_stopping_rounds: 100

# 7ï¸âƒ£ training: â†’ Model Training Settings

# ğŸ’¡ What it does:

# shift_period: 1 â†’ Predict next hour (cnt.shift(-1))
# train_fraction: 0.85 â†’ Use 85% for training
# early_stopping_rounds: 100 â†’ Stop if no improvement

# ğŸ¯ Why?

# So you can try train_fraction: 0.8 or 0.9 â€” no code change.


  optuna:
    n_trials: 5
    search_space:
      learning_rate:
        low: 0.01
        high: 0.2
        log: false
      depth:
        low: 3
        high: 8
      l2_leaf_reg:
        low: 0.5
        high: 5
        log: false

# 8ï¸âƒ£ optuna: â†’ Hyperparameter Search

# ğŸ’¡ What it does:

# Tells Optuna: "Try 5 trials, with learning_rate between 0.01 and 0.2"

# ğŸ¯ Why?

# So you can increase n_trials: 50 later â€” without editing code.

# ______________________________________________________________________________________________________________________

# ğŸ› ï¸ Example: Want to Change Model Path?
# Instead of editing code, just change:

# model_path: 'models/prod/latest_model'

# to:

# model_path: 'models/v2/best_model'
# âœ… Done â€” no code change.
